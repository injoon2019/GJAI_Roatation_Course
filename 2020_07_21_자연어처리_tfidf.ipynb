{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 리스트 출력:\n",
      "['안녕하세요', '감사해요', '잘있어요', '다시', '만나요', '안녕하세요', '오늘', '도', '좋은', '하루', '보내세요', '안녕하세요', '안녕하세요', '안녕하세요', '오늘', '도', '날씨', '가', '좋네요']\n",
      "   오늘  날씨  가  안녕하세요  도  잘있어요  다시  좋네요  감사해요  좋은  만나요  하루  보내세요\n",
      "0   0   0  0      0  0     0   0    0     0   0    0   0     0\n",
      "1   0   0  0      0  1     0   0    0     0   0    0   0     0\n",
      "2   0   0  1      0  1     0   0    0     0   0    0   0     0\n",
      "       idf\n",
      "오늘     NaN\n",
      "날씨     NaN\n",
      "가      NaN\n",
      "안녕하세요  NaN\n",
      "도      NaN\n",
      "잘있어요   NaN\n",
      "다시     NaN\n",
      "좋네요    NaN\n",
      "감사해요   NaN\n",
      "좋은     NaN\n",
      "만나요    NaN\n",
      "하루     NaN\n",
      "보내세요   NaN\n",
      "Empty DataFrame\n",
      "Columns: [오늘, 날씨, 가, 안녕하세요, 도, 잘있어요, 다시, 좋네요, 감사해요, 좋은, 만나요, 하루, 보내세요]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "doc_list = [\n",
    "    '안녕하세요 감사해요 잘있어요 다시 만나요',\n",
    "    '안녕하세요 오늘도 좋은 하루 보내세요',\n",
    "    '안녕하세요 안녕하세요 안녕하세요 오늘도 날씨가 좋네요',\n",
    "]\n",
    "\n",
    "#document 전체를 합쳐서 계산하기 편하게\n",
    "token_list = Okt().morphs(' '.join(doc_list))\n",
    "print(\"토큰 리스트 출력:\")\n",
    "print(token_list)\n",
    "token_list = list(set(token_list))\n",
    "\n",
    "def tf(term, document):\n",
    "    # document 에서 term 의 등장 횟수를 count\n",
    "    count = 0\n",
    "    for i in document:\n",
    "        if i==term:\n",
    "            count +=1\n",
    "    return count\n",
    "    \n",
    "def idf(term):\n",
    "    # doc_list 에서 term 이 등장한 문서 수를 count\n",
    "    count = 0\n",
    "    for i in doc_list:\n",
    "        if term in i:\n",
    "            count +=1    \n",
    "    return count\n",
    "\n",
    "def tfidf(term, document):\n",
    "    # tf * idf\n",
    "    tf = tf(term, document)\n",
    "    idf = idf(term)\n",
    "    return tf*idf\n",
    "\n",
    "dtm = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    # document term matrix (문서별 단어 등장 횟수) 를 구현해보자, 3 (문서) x 13 (단어) 의 행렬을 리스트로 구성하면 된다\n",
    "    temp_arr = []\n",
    "    for i in token_list:\n",
    "        temp_arr.append(tf(i,doc))\n",
    "    dtm.append(temp_arr)\n",
    "\n",
    "dtm_pd = pd.DataFrame(dtm, columns=token_list)\n",
    "print(dtm_pd)\n",
    "\n",
    "idf_list = []\n",
    "\n",
    "for token in token_list:\n",
    "    # 위 idf 함수를 이용하면 된다\n",
    "    pass\n",
    "idf_pd = pd.DataFrame(idf_list, columns=['idf'], index=token_list)\n",
    "print(idf_pd)\n",
    "\n",
    "tfidf_list = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    # tfidf 를 구현해보자, 3 (문서) x 13 (단어) 의 행렬을 리스트로 구성하면 된다\n",
    "    # 내부의 요소는 모두 tfidf 값으로 구성\n",
    "    pass\n",
    "\n",
    "tfidf_pd = pd.DataFrame(tfidf_list, columns=token_list)\n",
    "print(tfidf_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
