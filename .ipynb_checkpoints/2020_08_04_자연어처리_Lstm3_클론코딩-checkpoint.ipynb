{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3gKt-N--Vpu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "IA9McPPQ-eoE",
    "outputId": "2ddc341e-77a8-4422-88ca-005d15a3b112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# preprocessing done\n",
      "# split done\n",
      "# tokenization done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#스팸 메일 데이터를 가지고 스팸인지 아닌지 판별하기 \n",
    "#encoding은 보통 utf-8, cp949로 하면되지만 이번 파일은 latin1\n",
    "spam_data =  pd.read_csv(\"spam.csv\", encoding=\"latin1\")\n",
    "#3, 4, 5 열 삭제 후 컬럼명 변경\n",
    "spam_data = spam_data.dropna(axis=1)\n",
    "spam_data.columns = [\"label\", \"mail\"]\n",
    "\n",
    "#ham, spam 숫자로 변경\n",
    "spam_data['label'] = spam_data['label'].replace('spam', 1)\n",
    "spam_data['label'] = spam_data['label'].replace(\"ham\", 0)\n",
    "\n",
    "#단어 아니면 삭제\n",
    "spam_data['mail'] = spam_data['mail'].str.replace(\"[^\\w]\", \" \")\n",
    "#혹시나 공백이 있으면\n",
    "spam_data['mail'] = spam_data['mail'].replace('', np.nan)\n",
    "spam_data['label'] = spam_data['label'].replace('', np.nan)\n",
    "\n",
    "#결측치 있으면 모두 제거\n",
    "spam_data = spam_data.dropna(how='any')\n",
    "\n",
    "print(\"# preprocessing done\")\n",
    "\n",
    "#test/train 스플릿\n",
    "mail_train, mail_test, y_train, y_test = train_test_split(spam_data['mail'], spam_data['label'], test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"# split done\")\n",
    "\n",
    "stopwords = ['a', 'an']\n",
    "\n",
    "#토근화 진행\n",
    "X_train = []\n",
    "for stc in mail_train:\n",
    "  token = []\n",
    "  words = stc.split()\n",
    "  for word in words:\n",
    "    if word not in stopwords:\n",
    "      token.append(word)\n",
    "  X_train.append(token)\n",
    "\n",
    "X_test =  []\n",
    "\n",
    "for stc in mail_test:\n",
    "  token = []\n",
    "  words = stc.split()\n",
    "  for word in words:\n",
    "    if word not in stopwords:\n",
    "      token.append(word)\n",
    "  X_test.append(token)\n",
    "\n",
    "print(\"# tokenization done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7ScGY4-2_9ZK",
    "outputId": "1016695f-8f2b-4eae-c2cb-9dee8a4af448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# int_encoding done\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# X_train 단어들을 토대로 정수 인덱스 설정\n",
    "# 빈도수가 높은 것부터 4000개만 정수 인덱스로 변환하겠다\n",
    "\n",
    "tokenizer = Tokenizer(7792)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "#위에서 설정된 정수 인덱스를 토대로 변환\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print(\"# int_encoding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "123tbSH2AazE",
    "outputId": "e154054b-a789-4442-bbdd-9efa456929c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7792\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "9gLLtFApAqaT",
    "outputId": "dd2e49fd-dd28-4bea-f412-574c68379672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7792\n",
      "4030\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#이거를 토대로 7792를 넣은 것이다!\n",
    "print(len(tokenizer.word_index))\n",
    "\n",
    "low_count = 0\n",
    "for word, word_count in tokenizer.word_counts.items():\n",
    "  if word_count == 1:\n",
    "    low_count +=1\n",
    "\n",
    "print(low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "orl4x9akBT0a",
    "outputId": "5370ce24-87aa-4462-8c5a-e94782d1acbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for data in X_train:\n",
    "  if max_length < len(data):\n",
    "    max_length = len(data)\n",
    "\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmzQfPopBfvf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 50\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXio9o44BrIR"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(7792, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "n9m2QIVQB34B",
    "outputId": "d0921ed7-327b-4c0d-f22e-f633860a33e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "140/140 [==============================] - 4s 28ms/step - loss: 0.2053 - acc: 0.9293 - val_loss: 0.0763 - val_acc: 0.9803\n",
      "Epoch 2/3\n",
      "140/140 [==============================] - 3s 25ms/step - loss: 0.0520 - acc: 0.9895 - val_loss: 0.0552 - val_acc: 0.9839\n",
      "Epoch 3/3\n",
      "140/140 [==============================] - 3s 25ms/step - loss: 0.0301 - acc: 0.9924 - val_loss: 0.0394 - val_acc: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ca38246a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer = 'rmsprop', metrics=['acc'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "7ZAjTAZhCDFb",
    "outputId": "63e50102-c0ae-4cc5-a5d9-395c60a3a64b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free \n",
      "[[0.07125384]]\n"
     ]
    }
   ],
   "source": [
    "sentence = input()\n",
    "#토큰화\n",
    "token_stc = sentence.split()\n",
    "#정수 인코딩\n",
    "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
    "#패딩\n",
    "pad_stc = pad_sequences(encode_stc, maxlen=50)\n",
    "\n",
    "score = model.predict(pad_stc)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYsZBL-cCWdR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
