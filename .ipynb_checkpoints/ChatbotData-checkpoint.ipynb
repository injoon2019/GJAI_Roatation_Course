{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2FWm0SKKZ_J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03bl3S5qqZrC"
   },
   "outputs": [],
   "source": [
    "chatbot = pd.read_csv(\"./drive/My Drive/ChatbotData.csv\")\n",
    "\n",
    "chatbot['Q'] = chatbot['Q'].str.replace(\"[^\\w]\", \" \")\n",
    "chatbot['A'] = chatbot['A'].str.replace(\"[^\\w]\", \" \")\n",
    "\n",
    "print(chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldgDJJZgqytI"
   },
   "outputs": [],
   "source": [
    "encoder_input, decoder_input, decoder_output = [], [], []\n",
    "\n",
    "for stc in chatbot['Q']:\n",
    "    encoder_input.append(stc.split())\n",
    "\n",
    "for stc in chatbot['A']:\n",
    "    decoder_input.append((\"<start> \"+stc).split())\n",
    "\n",
    "for stc in chatbot['A']:\n",
    "    decoder_output.append((stc+\" <end>\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YqTq0f4rVNW"
   },
   "outputs": [],
   "source": [
    "tokenizer_q = Tokenizer()\n",
    "tokenizer_q.fit_on_texts(encoder_input)\n",
    "encoder_input = tokenizer_q.texts_to_sequences(encoder_input)\n",
    "\n",
    "tokenizer_a = Tokenizer()\n",
    "tokenizer_a.fit_on_texts(decoder_input)\n",
    "tokenizer_a.fit_on_texts(decoder_output)\n",
    "decoder_input = tokenizer_a.texts_to_sequences(decoder_input)\n",
    "decoder_output = tokenizer_a.texts_to_sequences(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITAo3Ecirn4v"
   },
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_output = pad_sequences(decoder_output, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9LHYsgNrsGr"
   },
   "outputs": [],
   "source": [
    "print(encoder_input[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2ugiyfMr1rU"
   },
   "outputs": [],
   "source": [
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxQh4t2hr6rI"
   },
   "outputs": [],
   "source": [
    "a_to_index = tokenizer_a.word_index\n",
    "index_to_a = tokenizer_a.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBbXzoPUsF17"
   },
   "outputs": [],
   "source": [
    "test_size = 2500\n",
    "encoder_input_train = encoder_input[:-test_size]\n",
    "decoder_input_train = decoder_input[:-test_size]\n",
    "decoder_output_train = decoder_output[:-test_size]\n",
    "\n",
    "encoder_input_test = encoder_input[-test_size:]\n",
    "decoder_input_test = decoder_input[-test_size:]\n",
    "decoder_output_test = decoder_output[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DVSJxA9sLKi"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nn-kjwNssLwu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DJkWSzusOuv"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(15,))\n",
    "encoder_embed = Embedding(len(tokenizer_q.word_index)+1, 50)(encoder_inputs)\n",
    "encoder_mask = Masking(mask_value=0)(encoder_embed)\n",
    "encoder_outputs, h_state, c_state = LSTM(50, return_state=True)(encoder_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1N9usf3sdCM"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(22,))\n",
    "decoder_embed = Embedding(len(tokenizer_a.word_index)+1, 50)(decoder_inputs)\n",
    "decoder_mask = Masking(mask_value=0)(decoder_embed)\n",
    "\n",
    "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_mask, initial_state=[h_state, c_state])\n",
    "\n",
    "decoder_dense = Dense(len(tokenizer_a.word_index)+1, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UN-PbzSns7bt"
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_output_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_output_test), batch_size = 128, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iN-yy4IvtS6E"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIA4caoxtTew"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, [h_state, c_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6AI9CQAtcs6"
   },
   "outputs": [],
   "source": [
    "encoder_h_state = Input(shape=(50,))\n",
    "encoder_c_state = Input(shape=(50,))\n",
    "\n",
    "pd_decoder_outputs, pd_h_state, pd_c_state = decoder_lstm(decoder_mask, initial_state=[encoder_h_state, encoder_c_state])\n",
    "pd_decoder_softmax_outputs = decoder_dense(pd_decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs, encoder_h_state, encoder_c_state], [pd_decoder_softmax_outputs, pd_h_state, pd_c_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvZUe4lUuYBb"
   },
   "outputs": [],
   "source": [
    "input_stc = input()\n",
    "token_stc = input_stc.split()\n",
    "encode_stc = tokenizer_q.texts_to_sequences([token_stc])\n",
    "pad_stc = pad_sequences(encode_stc, maxlen=15, padding=\"post\")\n",
    "\n",
    "states_value = encoder_model.predict(pad_stc)\n",
    "\n",
    "predicted_seq = np.zeros((1,1))\n",
    "predicted_seq[0, 0] = a_to_index['<start>']\n",
    "print(predicted_seq)\n",
    "\n",
    "decoded_stc = []\n",
    "\n",
    "while True:\n",
    "    output_words, h, c = decoder_model.predict([predicted_seq] + states_value)\n",
    "\n",
    "    predicted_word = index_to_a[np.argmax(output_words[0,0])]\n",
    "\n",
    "    if predicted_word == '<end>':\n",
    "        break\n",
    "\n",
    "    decoded_stc.append(predicted_word)\n",
    "\n",
    "    predicted_seq = np.zeros((1,1))\n",
    "    predicted_seq[0,0] = np.argmax(output_words[0,0])\n",
    "\n",
    "    states_value = [h, c]\n",
    "\n",
    "print(' '.join(decoded_stc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ChatbotData.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
