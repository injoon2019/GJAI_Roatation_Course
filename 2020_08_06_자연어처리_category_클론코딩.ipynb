{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Flatten, Concatenate, Input, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        category                                           headline\n",
      "0              0  There Were 2 Mass Shootings In Texas Last Week...\n",
      "1              1  Will Smith Joins Diplo And Nicky Jam For The 2...\n",
      "2              1    Hugh Grant Marries For The First Time At Age 57\n",
      "3              1  Jim Carrey Blasts 'Castrato' Adam Schiff And D...\n",
      "4              1  Julianna Margulies Uses Donald Trump Poop Bags...\n",
      "...          ...                                                ...\n",
      "200848        14  RIM CEO Thorsten Heins' 'Significant' Plans Fo...\n",
      "200849        10  Maria Sharapova Stunned By Victoria Azarenka I...\n",
      "200850        10  Giants Over Patriots, Jets Over Colts Among  M...\n",
      "200851        10  Aldon Smith Arrested: 49ers Linebacker Busted ...\n",
      "200852        10  Dwight Howard Rips Teammates After Magic Loss ...\n",
      "\n",
      "[200853 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#json 읽어오기\n",
    "news_data = pd.read_json(r'C:\\Users\\injoo\\광주 인공지능 사관학교\\로테이션\\자연어처리&추천시스템 김준태\\News_Category_Dataset_v2.json', lines=True)\n",
    "#print(news_data)\n",
    "news_data = news_data.loc[:, [\"category\", \"headline\"]]\n",
    "\n",
    "#카테고리 정수 인코딩\n",
    "#news_data['category'] = news_data['category'].replace(~~, ~)\n",
    "# print(pd.factorize(news_data['category']))\n",
    "category_list = pd.factorize(news_data['category'])[1]\n",
    "news_data['category'] = pd.factorize(news_data['category'])[0]\n",
    "\n",
    "print(news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식 사용\n",
    "news_data['headline'] =  news_data['headline'].str.replace(\"[^\\w]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split하면서 shuffle 적용\n",
    "news_train, news_test, y_train, y_test = train_test_split(news_data['headline'], news_data['category'], test_size=0.2, shuffle=True, random_state=23)\n",
    "\n",
    "# 원핫벡터로 만들어줍시다! (num_classes로 카테고리 수 명시 가능)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(len(y_train[0]))\n",
    "print(len(y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화 진행\n",
    "stopwords = ['a', 'an']\n",
    "\n",
    "X_train = []\n",
    "for stc in news_train:\n",
    "    token = []\n",
    "    words = stc.split()\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_train.append(token)\n",
    "    \n",
    "X_test = []\n",
    "for stc in news_test:\n",
    "    token = []\n",
    "    words = stc.split()\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            token.append(word)\n",
    "    X_test.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 헤드라인 정수인코딩\n",
    "tokenizer = Tokenizer(25000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50923\n",
      "26916\n"
     ]
    }
   ],
   "source": [
    "#여기서 빈도수가 2 이하인 단어들의 개수가 26900개, 전체 단어 개수가 50923개 이니 위에 25000개 대략 넣은 것\n",
    "print(len(tokenizer.word_index))\n",
    "\n",
    "wc = 0\n",
    "for word, word_count in tokenizer.word_counts.items():\n",
    "    if word_count <=2:\n",
    "        wc +=1\n",
    "print(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "len_stc = []\n",
    "for data in X_train:\n",
    "    len_stc.append(len(data))\n",
    "\n",
    "y, x , _= plt.hist(len_stc, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 15\n",
    "#max_len을 위 히스토그램에서 15로 잡고, padding 해주는 것\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(25000, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(41, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2106/2511 [========================>.....] - ETA: 14s - loss: 2.0624 - acc: 0.4607"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = input()\n",
    "token_stc = sentence.split()\n",
    "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
    "pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
    "\n",
    "score = model.predict(pad_stc)\n",
    "print(category_list[score.argmax()], score[0, score.argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트위터 감정 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tweet_data = pd.read_csv(r'C:\\Users\\injoo\\광주 인공지능 사관학교\\로테이션\\자연어처리&추천시스템 김준태\\tweet_dataset.csv')\n",
    "tweet_data = tweet_data.loc[:, [\"sentiment\", \"text\"]]\n",
    "tweet_data = tweet_data.dropna(how='any')\n",
    "\n",
    "#감정 인코딩\n",
    "print(pd.factorize(tweet_data['sentiment']))\n",
    "tweet_data['sentiment'] = pd.factorize(tweet_data['sentiment'])[0]\n",
    "print(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규표현식 써서 단어 아니면 삭제\n",
    "tweet_data['text'] = tweet_data['text'].str.replace(\"[^\\w]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train 스플릿\n",
    "tweet_train, tweet_test, y_train, y_test = train_test_split(tweet_data['text'], tweet_data['sentiment'], test_size=0.2, shuffle = True, random_state=23)\n",
    "\n",
    "#원핫벡터화\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(len(y_train[0]))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "#nltk stopwords 리스트\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "#토큰화 진행\n",
    "X_train = []\n",
    "for stc in tweet_train:\n",
    "    token = []\n",
    "    words = WordPunctTokenizer().tokenize(stc)\n",
    "    for word in words:\n",
    "        if word.lower() not in stopwords:\n",
    "            token.append(word.lower())\n",
    "    X_train.append(token)\n",
    "\n",
    "X_test=  []\n",
    "for stc in tweet_test:\n",
    "    token = []\n",
    "    words = WordPunctTokenizer().tokenize(stc)\n",
    "    for word in words:\n",
    "        if word.lower() not in stopwords:\n",
    "            token.append(word.lower())\n",
    "    X_test.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#트윗 정수인코딩\n",
    "tokenizer = Tokenizer(10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokenizer.word_index))\n",
    "low_count = 0\n",
    "for word, word_count in tokenizer.word_counts.items():\n",
    "    if word_count > 1:\n",
    "        low_count +=1\n",
    "print(low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 최대 길이 구하기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "len_stc = []\n",
    "for data in X_train:\n",
    "    len_stc.append(len(data))\n",
    "\n",
    "y, x, _ = plt.hist(len_stc)\n",
    "plt.show()\n",
    "print(sum(len_stc)/len(len_stc))\n",
    "print(y.max())\n",
    "print(x.max())\n",
    "print(x[np.where(y== y.max())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 25\n",
    "X_train = pad_sequences(X_train, maxlen= max_len)\n",
    "X_test  = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(13, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수형 케라스\n",
    "inputs = Input(shape=(25, ))\n",
    "embed = Embedding(10000, 32)(inputs)\n",
    "drop = Dropout(0.3)(embed)\n",
    "\n",
    "#모델 합성\n",
    "concat_layers = []\n",
    "\n",
    "conv = Conv1D(32, 1, padding=\"same\", activation='relu')(drop)\n",
    "pool = GlobalMaxPooling1D()(conv)\n",
    "flat = Flatten()(pool)\n",
    "concat_layers.append(flat)\n",
    "\n",
    "conv = Conv1D(32, 2, padding=\"same\", activation='relu')(drop)\n",
    "pool = GlobalMaxpooling1D()(conv)\n",
    "flat = Flatten()(pool)\n",
    "concat_layers.append(flat)\n",
    "#####\n",
    "concat = Concatenate()(concat_layers)\n",
    "relu = Dense(64, activation='relu')(concat)\n",
    "drop = Dropout(0, 5)(relu)\n",
    "\n",
    "outputs = Dense(13, activation = \"softmax\")(drop)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='catego')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
